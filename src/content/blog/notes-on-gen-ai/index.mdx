---
title: "notes on Generative AI: luddites, effective accelerationism™, critical AI"
description: "me when i write things"
pubDate: "Nov 19 2023"
tags: ["writing"]
---

this doc is still being written! i may change my ideass

## Introduction

Growing up in a startup-oriented technosphere of Seattle, I've been "indoctrinated" so to speak on the wonders and universalism of american digital technology. Since then I have been detaching myself from those spaces, venturing into alternative online communities and re-engaging with critical studies. Especially in a post-crypto and post-metaverse world, I have grown hyper-critical of anything coming out of the Silicon Valley.

With the advent of the modern "AI", I am forced to deeply re-think my politics and ideals, and I write in search for any answers.

## Critical Realisms: You cannot ignore labor

What i found frustrating about views on generative AI, especially among conceptual/new media artists, is how positive they view the technology given the absolute rejection of these tools from commercial illustrator and artists.

These technologies developed in the silicon valley are affecting people right now, across the world, and to me it seems impossible to simply ignore those. At a time when the american labor rights movement has been the largest since the 1950s, with the SAG-AFTRA writers and actors striking for protection against AI, how can you not stand in solidarity with your fellow artists?

This is what I have most issue with from the article "'can computers be creative?' a misguided question" in which the author posits that we need to take a post-humanist angle to creativity, as we have always used non-human entities to create art with.

I believe this argument is a strawman to the actual issues that workers and artists have over generative AI. People do not necessarily care about whether computers are creative, rather this question is a proxy for labor: will this take my job away?

The Editor Lauren M. E. Goodlad's introduction to the new interdisciplinary journal [_Critial AI_ from Duke University Press](https://www.dukeupress.edu/critical-ai) argues the same (in a more academic and well written way), in a concept they refer as _**critical realism**_:

> The long histories of “the humanities” and of “the human” are, to be sure, plagued by many problems, most of which have been extensively documented by deconstructionists, feminists, postcolonial theorists, and critical race scholars during the last several decades. **But that does not mean we can rectify these problems or, still less, address present crises by ignoring the human-dominated structures of power that enable the status quo.**[^humanloop]

[^humanloop]:
    Lauren M. E. Goodlad, "Editor's Introduction: Humanities in the Loop" (emphasis mine btw)
    https://doi.org/10.1215/2834703X-10734016

The paper [_AI Art and its Impact on Artists_](https://dl.acm.org/doi/10.1145/3600211.3604681) from august 2023 details how modern generative AI systems currently affect artists, ranging from Economic Loss, Digital Artwork Forgery, and Stereotyping. Ultimatly, they argue this has "chilling impacts" on how people produce and consume art. artists, who's work requires visibility online, are more reluctant to share their work online.

### aside: luddites etc.

As with any new technology, this conversation always begins with some allusions to the luddites, and their protest against automation.

even modern conversations of luddites still carry this idea of failed anti-innovation prudes who lost to the clear gains from technological innovation. Silicon valley loves to refrence them whenever anyone doubts or critiques the software they develop. I think most ironically, the crypto superbowl commercial from FTX[^cryptosuperbowl] features this mindset.

[^cryptosuperbowl]: https://www.nytimes.com/2022/02/13/business/media/larry-david-super-bowl-ftx-crypto.html

A brief look at history does reveal that luddites were much more pragmatic and logical in their protests[^luddites]. As skilled machinery workers, they were not really concerned with these new machines, but rather they took issue with the capitalist's attempt to circumvent labor practices of the time[^luddites2].

The luddites were met with intense state violence: 12,000[^luddites4] troops from the British government were deployed to suppress this uprising. Historians mark this as the cause for the decline of the luddite movement[^luddites3], not that they were left behind by technology, as is often implied in modern arguments.

[^luddites]: https://www.smithsonianmag.com/history/what-the-luddites-really-fought-against-264412/
[^luddites2]: https://www.historic-uk.com/HistoryUK/HistoryofBritain/The-Luddites/
[^luddites3]: https://www.historyextra.com/period/industrial-revolution/who-were-luddites-facts-what-happened/
[^luddites4]: i got this number from wikipedia, but they cite this: Hobsbawm, E. J. (1952). "The Machine Breakers". Past & Present. 1 (1): 57–70. doi:10.1093/past/1.1.57.

## consequences of AI in labor

### Fauxautomation in the year of Generative AI

> As this special issue goes into production, the Writers Guild of America is on strike, partly to negotiate terms governing the use of automated writing. That is not because chatbots write good screenplays, but rather because studios can portray automated texts as first “drafts” so as to pay writers a lower rate for “revising” them, even though such “revision” is usually more laborious than writing from scratch.20 This is but one of the many deceptions of “AI.”[^humanloop]

### labor relations with machine learning

From _Labour, Automation, and Human-Machine Communication_ by Julian Posada, Gemma Newlands, Milagros Miceli, https://www.dair-institute.org/

> the implementation of AI in the workplace does not only pursue productive outcomes: It also serves to control, transform, and intermediate the labour process. [...]the development of these algorithms is strongly shaped by power relations. Those power relations manifest in the deployment of such algorithms as mechanisms of control.

algorythm controls workers by:

1. restricting worker agency and
   recommending actions to direct workers
2. recording and rating workers to evaluate them,
3. replacing or rewarding them to discipline the workforce

## effects of "AI"

From the paper "_How to Make “AI” Intelligent; or, The Question of Epistemic Equality_"[^intelligence], Newfield discusses commmon operational flaws of "AI":

1.  social biases, particularly racism;
2.  opacity, such that users cannot assess how results were generated;
3.  coercion, in that architectures, datasets, algorithms, and the like are controlled by designers and platforms rather than users;
4.  systemic privacy violations;
5.  the absence of academic freedom covering corporation-based research, such that results can be hyped in accordance with business objectives or suppressed and distorted if not.

Newfield then argues that there is a 6th catagory, focusing on the term "intelligence" and how this hinders productive discussions of the technology. They instead argue

[^intelligence]: https://doi.org/10.1215/2834703X-10734076

## weird ideologies of silicon valley: effective accelerationism

a new reactionary ideology is gaining steam in silicon valley:

in short, its "progress should stop at nothing" and it was developed in reaction to effective altruism, which seems to care about AI safety (regardless of how crit-hype they are)

on one hand, this is an "ideology" thats [not taken seriously in academic fields.](https://www.reddit.com/r/CriticalTheory/comments/171mbo3/thoughts_on_effective_accelerationism/)

but on the other, this is [something that has taken hold](https://www.businessinsider.com/silicon-valley-tech-leaders-accelerationism-eacc-twitter-profiles-2023-7?r=US&IR=T) within the non-humanities, non-academic silicon valley fields

theres [similar thoughts spouted by the likes of peter thiel](https://www.newyorker.com/news/letter-from-silicon-valley/what-is-it-about-peter-thiel), and also this is reflected in many silicon valley companies [argument for unrestrained innovation](https://www.ft.com/content/2ed278cc-6c3f-4569-b73c-64ad378f3ea8) in fear of china's own tech industry.

Theres fear of monopolization of the "barons of silicon valley" that scares people, as [written by Rana Foobar](https://www.ft.com/content/4d18d7eb-ce97-4121-abd8-64e3bee958db):

>     But what worries me more is a false narrative that’s been put forward by US tech titans that they shouldn’t be too tightly regulated because they are the “national champions” in a technological fight with China.

Theres this whitepaper (which btw, is every report now a whitepaper? what is even a whitepaper) from a left-of-center thinktank open market institute (thinktank - so take with a grain of salt) about [the monopolization of AI and technology](https://www.openmarketsinstitute.org/publications/report-ai-in-the-public-interest-confronting-the-monopoly-threat).

they argue thus:

1. AI is a function of concentrated technological
   capacities and capabilities
2. Monopolists are exploiting existing advantages to
   shape and speed the rollout of AI
3. Monopolists are using AI to further entrench their
   existing dominance.

## Scrapism: where do we go from here?

I am primarily drawing from the publication _Critical AI_ and the _Distributed AI Research Institute (DAIR)_ as reference, alongside technologist and lecturer lizthedev.

On their tiktok page, lizthedev argues persuasively that generative ai and other machine learning programs from the heart of the silicon valley are inevitable, due to the capital and ideology that the people running these companies possess. They argue therefore, that we the working class must adapt and take advantage as much as possible this technology, otherwise we will only be widening the gap between the boursuasie and proletariat class.
[^lizthedev]
to demonstrate this, liz [created a site to help people make resumes and coverletters](https://hackingcapitalism.dev/) using chatGipity
[^lizthedev]: https://www.lizthe.dev/

From _Scrapism: A Manifesto_ by Sam Lavigne[^scrapism]

> Scrapism is always, at minimum, a two-step process: it involves programmatically collecting material and then repurposing or re-presenting that material outside its original proprietary context.

> For “Synthetic Messenger” (Lavigne and Brain n.d.), Tega Brain and I used a similar technique to create a program that clicked on millions of ads shown next to online news articles about climate change (fig. 1). Our goal was both to comment on the way that media ecology shapes physical ecology and to financially incentivize media outlets to cover climate news by engaging in what the ad industry calls “click fraud.”

> For example, in “New York Apartment” (Lavigne and Brain n.d.), Tega Brain and I collaborated in downloading the entirety of the New York real estate market from Trulia, and then we combined it in a single site to create a holistic experience of housing-as-commodity (fig. 3). Using GoFundMe, I downloaded and sorted two hundred thousand supportive comments from medical fundraiser pages to archive the collective experience of health care-as-commodity. And, by accessing LinkedIn data, I compiled a list of Immigration and Customs Enforcement (ICE) agents to produce an archive of those who are implicated in the US government's ongoing program of human rights violations.

> In some cases, “activating” an archive for political purposes also necessitates its creation. For example, in “White Collar Crime Risk Zones” (Lavigne, Clifton, and Tseng n.d.), my collaborators and I produced a fully functional predictive policing tool that targets financial crime in the United States (fig. 4).

> Scrapism is an invitation to engage with these traces. It attempts to reopen these opaque systems, share proprietary knowledge, leverage data against the logic of extraction, and open the structures of digital capitalism to the public's surveillance. As Berners-Lee says, “perhaps a linked information system will allow us to see the real structure of the organization in which we work.”

[^scrapism]: https://doi.org/10.1215/2834703X-10734046
